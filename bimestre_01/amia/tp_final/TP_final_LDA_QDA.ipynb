{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AUTORES**\n",
    "* Mauro Barquinero\n",
    "* Yandri Uchuari\n",
    "* Marck Murillo\n",
    "* Matias Tripode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bpJ7s_SIVu_I"
   },
   "source": [
    "# Trabajo Práctico Final: Linear/Quadratic Discriminant Analysis (LDA/QDA)\n",
    "\n",
    "### Definición: Clasificador Bayesiano\n",
    "\n",
    "Sean $k$ poblaciones, $x \\in \\mathbb{R}^p$ puede pertenecer a cualquiera $g \\in \\mathcal{G}$ de ellas. Bajo un esquema bayesiano, se define entonces $\\pi_j \\doteq P(G = j)$ la probabilidad *a priori* de que $X$ pertenezca a la clase *j*, y se **asume conocida** la distribución condicional de cada observable dado su clase $f_j \\doteq f_{X|G=j}$.\n",
    "\n",
    "De esta manera dicha probabilidad *a posteriori* resulta\n",
    "$$\n",
    "P(G|_{X=x} = j) = \\frac{f_{X|G=j}(x) \\cdot p_G(j)}{f_X(x)} \\propto f_j(x) \\cdot \\pi_j\n",
    "$$\n",
    "\n",
    "La regla de decisión de Bayes es entonces\n",
    "$$\n",
    "H(x) \\doteq \\arg \\max_{g \\in \\mathcal{G}} \\{ P(G|_{X=x} = j) \\} = \\arg \\max_{g \\in \\mathcal{G}} \\{ f_j(x) \\cdot \\pi_j \\}\n",
    "$$\n",
    "\n",
    "es decir, se predice a $x$ como perteneciente a la población $j$ cuya probabilidad a posteriori es máxima.\n",
    "\n",
    "*Ojo, a no desesperar! $\\pi_j$ no es otra cosa que una constante prefijada, y $f_j$ es, en su esencia, un campo escalar de $x$ a simplemente evaluar.*\n",
    "\n",
    "### Distribución condicional\n",
    "\n",
    "Para los clasificadores de discriminante cuadrático y lineal (QDA/LDA) se asume que $X|_{G=j} \\sim \\mathcal{N}_p(\\mu_j, \\Sigma_j)$, es decir, se asume que cada población sigue una distribución normal.\n",
    "\n",
    "Por definición, se tiene entonces que para una clase $j$:\n",
    "$$\n",
    "f_j(x) = \\frac{1}{(2 \\pi)^\\frac{p}{2} \\cdot |\\Sigma_j|^\\frac{1}{2}} e^{- \\frac{1}{2}(x-\\mu_j)^T \\Sigma_j^{-1} (x- \\mu_j)}\n",
    "$$\n",
    "\n",
    "Aplicando logaritmo (que al ser una función estrictamente creciente no afecta el cálculo de máximos/mínimos), queda algo mucho más práctico de trabajar:\n",
    "\n",
    "$$\n",
    "\\log{f_j(x)} = -\\frac{1}{2}\\log |\\Sigma_j| - \\frac{1}{2} (x-\\mu_j)^T \\Sigma_j^{-1} (x- \\mu_j) + C\n",
    "$$\n",
    "\n",
    "Observar que en este caso $C=-\\frac{p}{2} \\log(2\\pi)$, pero no se tiene en cuenta ya que al tener una constante aditiva en todas las clases, no afecta al cálculo del máximo.\n",
    "\n",
    "### LDA\n",
    "\n",
    "En el caso de LDA se hace una suposición extra, que es $X|_{G=j} \\sim \\mathcal{N}_p(\\mu_j, \\Sigma)$, es decir que las poblaciones no sólo siguen una distribución normal sino que son de igual matriz de covarianzas. Reemplazando arriba se obtiene entonces:\n",
    "\n",
    "$$\n",
    "\\log{f_j(x)} =  -\\frac{1}{2}\\log |\\Sigma| - \\frac{1}{2} (x-\\mu_j)^T \\Sigma^{-1} (x- \\mu_j) + C\n",
    "$$\n",
    "\n",
    "Ahora, como $-\\frac{1}{2}\\log |\\Sigma|$ es común a todas las clases se puede incorporar a la constante aditiva y, distribuyendo y reagrupando términos sobre $(x-\\mu_j)^T \\Sigma^{-1} (x- \\mu_j)$ se obtiene finalmente:\n",
    "\n",
    "$$\n",
    "\\log{f_j(x)} =  \\mu_j^T \\Sigma^{-1} (x- \\frac{1}{2} \\mu_j) + C'\n",
    "$$\n",
    "\n",
    "### Entrenamiento/Ajuste\n",
    "\n",
    "Obsérvese que para ambos modelos, ajustarlos a los datos implica estimar los parámetros $(\\mu_j, \\Sigma_j) \\; \\forall j = 1, \\dots, k$ en el caso de QDA, y $(\\mu_j, \\Sigma)$ para LDA.\n",
    "\n",
    "Estos parámetros se estiman por máxima verosimilitud, de manera que los estimadores resultan:\n",
    "\n",
    "* $\\hat{\\mu}_j = \\bar{x}_j$ el promedio de los $x$ de la clase *j*\n",
    "* $\\hat{\\Sigma}_j = s^2_j$ la matriz de covarianzas estimada para cada clase *j*\n",
    "* $\\hat{\\pi}_j = f_{R_j} = \\frac{n_j}{n}$ la frecuencia relativa de la clase *j* en la muestra\n",
    "* $\\hat{\\Sigma} = \\frac{1}{n} \\sum_{j=1}^k n_j \\cdot s^2_j$ el promedio ponderado (por frecs. relativas) de las matrices de covarianzas de todas las clases. *Observar que se utiliza el estimador de MV y no el insesgado*\n",
    "\n",
    "Es importante notar que si bien todos los $\\mu, \\Sigma$ deben ser estimados, la distribución *a priori* puede no inferirse de los datos sino asumirse previamente, utilizándose como entrada del modelo.\n",
    "\n",
    "### Predicción\n",
    "\n",
    "Para estos modelos, al igual que para cualquier clasificador Bayesiano del tipo antes visto, la estimación de la clase es por método *plug-in* sobre la regla de decisión $H(x)$, es decir devolver la clase que maximiza $\\hat{f}_j(x) \\cdot \\hat{\\pi}_j$, o lo que es lo mismo $\\log\\hat{f}_j(x) + \\log\\hat{\\pi}_j$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5TDWOgpJWKQa"
   },
   "source": [
    "## Estructura del código"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6yEV8WbiWl6k"
   },
   "source": [
    "## Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "id": "teF9O9JJmG7Z"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import det, inv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTAS**\n",
    "\n",
    "**Clase ClassEncoder**\n",
    "* Convierte las etiquetas de las clases en números enteros para facilitar los cálculos.\n",
    "Proporciona un mapeo entre las etiquetas originales de las clases y los números enteros codificados, lo que permite que las predicciones se devuelvan en su forma original.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "id": "sDBLvbTtlwzs"
   },
   "outputs": [],
   "source": [
    "class ClassEncoder:\n",
    "  def fit(self, y):\n",
    "    self.names = np.unique(y)\n",
    "    self.name_to_class = {name:idx for idx, name in enumerate(self.names)}\n",
    "    self.fmt = y.dtype\n",
    "    # Q1: por que no hace falta definir un class_to_name para el mapeo inverso?\n",
    "\n",
    "  def _map_reshape(self, f, arr):\n",
    "    return np.array([f(elem) for elem in arr.flatten()]).reshape(arr.shape)\n",
    "    # Q2: por que hace falta un reshape?\n",
    "\n",
    "  def transform(self, y):\n",
    "    return self._map_reshape(lambda name: self.name_to_class[name], y)\n",
    "\n",
    "  def fit_transform(self, y):\n",
    "    self.fit(y)\n",
    "    return self.transform(y)\n",
    "\n",
    "  def detransform(self, y_hat):\n",
    "    return self._map_reshape(lambda idx: self.names[idx], y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "id": "m0KYC8_uSOu4"
   },
   "outputs": [],
   "source": [
    "class BaseBayesianClassifier:\n",
    "  def __init__(self):\n",
    "    self.encoder = ClassEncoder()\n",
    "\n",
    "  def _estimate_a_priori(self, y):\n",
    "    a_priori = np.bincount(y.flatten().astype(int)) / y.size\n",
    "    # Q3: para que sirve bincount?\n",
    "    # R3: np.bincount cuenta la cantidad de ocurrencias de cada valor entero en un arreglo unidimensional. \n",
    "    # En el contexto del método _estimate_a_priori, se utiliza para contar cuántas muestras pertenecen a cada clase, \n",
    "    # dado que las clases han sido previamente codificadas como enteros (por ejemplo, 0, 1, 2, etc.).\n",
    "    return np.log(a_priori)\n",
    "\n",
    "  def _fit_params(self, X, y):\n",
    "    # estimate all needed parameters for given model\n",
    "    raise NotImplementedError()\n",
    "\n",
    "  def _predict_log_conditional(self, x, class_idx):\n",
    "    # predict the log(P(x|G=class_idx)), the log of the conditional probability of x given the class\n",
    "    # this should depend on the model used\n",
    "    raise NotImplementedError()\n",
    "\n",
    "  def fit(self, X, y, a_priori=None):\n",
    "    # first encode the classes\n",
    "    y = self.encoder.fit_transform(y)\n",
    "\n",
    "    # if it's needed, estimate a priori probabilities\n",
    "    self.log_a_priori = self._estimate_a_priori(y) if a_priori is None else np.log(a_priori)\n",
    "\n",
    "    # check that a_priori has the correct number of classes\n",
    "    assert len(self.log_a_priori) == len(self.encoder.names), \"A priori probabilities do not match number of classes\"\n",
    "\n",
    "    # now that everything else is in place, estimate all needed parameters for given model\n",
    "    self._fit_params(X, y)\n",
    "    # Q4: por que el _fit_params va al final? no se puede mover a, por ejemplo, antes de la priori?\n",
    "    # R4: La función _fit_params se ejecuta después de calcular las probabilidades a priori porque:\n",
    "    # - Se necesita que las clases ya estén codificadas en enteros mediante self.encoder.fit_transform(y). Esto asegura que cada clase esté correctamente mapeada para los cálculos, como medias y covarianzas.\n",
    "    # - Antes de calcular parámetros como las medias y matrices de covarianza por clase, es necesario verificar que el número de clases coincida con las probabilidades a priori estimadas. Este chequeo se realiza justo antes de _fit_params.\n",
    "\n",
    "  def predict(self, X):\n",
    "    # this is actually an individual prediction encased in a for-loop\n",
    "    m_obs = X.shape[1]\n",
    "    y_hat = np.empty(m_obs, dtype=self.encoder.fmt)\n",
    "\n",
    "    for i in range(m_obs):\n",
    "      encoded_y_hat_i = self._predict_one(X[:,i].reshape(-1,1))\n",
    "      y_hat[i] = self.encoder.names[encoded_y_hat_i]\n",
    "\n",
    "    # return prediction as a row vector (matching y)\n",
    "    return y_hat.reshape(1,-1)\n",
    "\n",
    "  def _predict_one(self, x):\n",
    "    # calculate all log posteriori probabilities (actually, +C)\n",
    "    log_posteriori = [ log_a_priori_i + self._predict_log_conditional(x, idx) for idx, log_a_priori_i\n",
    "                  in enumerate(self.log_a_priori) ]\n",
    "\n",
    "    # return the class that has maximum a posteriori probability\n",
    "    return np.argmax(log_posteriori)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "id": "IRamFdiGDuSR"
   },
   "outputs": [],
   "source": [
    "class QDA(BaseBayesianClassifier):\n",
    "\n",
    "  def _fit_params(self, X, y):\n",
    "    # estimate each covariance matrix\n",
    "    self.inv_covs = [inv(np.cov(X[:,y.flatten()==idx], bias=True))\n",
    "                      for idx in range(len(self.log_a_priori))]\n",
    "    # Q5: por que hace falta el flatten y no se puede directamente X[:,y==idx]?\n",
    "    # R5: Asegura que y sea un arreglo unidimensional para facilitar el indexado y las comparaciones.\n",
    "\n",
    "    # Q6: por que se usa bias=True en vez del default bias=False?\n",
    "    # R6: El bias=True en np.cov: Se alinea con el supuesto de que los datos provienen de una \n",
    "    # distribución gaussiana, donde las matrices de covarianza se normalizan por el número total de muestras.\n",
    "    self.means = [X[:,y.flatten()==idx].mean(axis=1, keepdims=True)\n",
    "                  for idx in range(len(self.log_a_priori))]\n",
    "    # Q7: que hace axis=1? por que no axis=0?\n",
    "    # R7: Calcula la media a lo largo de las muestras para cada característica (columna).\n",
    "\n",
    "  def _predict_log_conditional(self, x, class_idx):\n",
    "    # predict the log(P(x|G=class_idx)), the log of the conditional probability of x given the class\n",
    "    # this should depend on the model used\n",
    "    inv_cov = self.inv_covs[class_idx]\n",
    "    unbiased_x =  x - self.means[class_idx]\n",
    "    return 0.5*np.log(det(inv_cov)) -0.5 * unbiased_x.T @ inv_cov @ unbiased_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "id": "fRtC9HEkO5Hu"
   },
   "outputs": [],
   "source": [
    "class TensorizedQDA(QDA):\n",
    "\n",
    "    def _fit_params(self, X, y):\n",
    "        # ask plain QDA to fit params\n",
    "        super()._fit_params(X,y)\n",
    "\n",
    "        # stack onto new dimension\n",
    "        self.tensor_inv_cov = np.stack(self.inv_covs)\n",
    "        self.tensor_means = np.stack(self.means)\n",
    "\n",
    "    def _predict_log_conditionals(self,x):\n",
    "        unbiased_x = x - self.tensor_means\n",
    "        inner_prod = unbiased_x.transpose(0,2,1) @ self.tensor_inv_cov @ unbiased_x\n",
    "\n",
    "        return 0.5*np.log(det(self.tensor_inv_cov)) - 0.5 * inner_prod.flatten()\n",
    "\n",
    "    def _predict_one(self, x):\n",
    "        # return the class that has maximum a posteriori probability\n",
    "        return np.argmax(self.log_a_priori + self._predict_log_conditionals(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KS_zoK-gWkRf"
   },
   "source": [
    "## Código para pruebas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nz19b6NJed2A"
   },
   "source": [
    "Seteamos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "id": "m05KrhUDINVs"
   },
   "outputs": [],
   "source": [
    "# hiperparámetros\n",
    "rng_seed = 6543"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2hkXcoldXOqs",
    "outputId": "2ce8d627-3433-4bdd-d370-85f6b703a7b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (150, 4), Y:(150, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris, fetch_openml\n",
    "\n",
    "def get_iris_dataset():\n",
    "  data = load_iris()\n",
    "  X_full = data.data\n",
    "  y_full = np.array([data.target_names[y] for y in data.target.reshape(-1,1)])\n",
    "  return X_full, y_full\n",
    "\n",
    "def get_penguins():\n",
    "    # get data\n",
    "    df, tgt = fetch_openml(name=\"penguins\", return_X_y=True, as_frame=True)\n",
    "\n",
    "    # drop non-numeric columns\n",
    "    df.drop(columns=[\"island\",\"sex\"], inplace=True)\n",
    "\n",
    "    # drop rows with missing values\n",
    "    mask = df.isna().sum(axis=1) == 0\n",
    "    df = df[mask]\n",
    "    tgt = tgt[mask]\n",
    "\n",
    "    return df.values, tgt.to_numpy().reshape(-1,1)\n",
    "\n",
    "# showing for iris\n",
    "X_full, y_full = get_iris_dataset()\n",
    "\n",
    "print(f\"X: {X_full.shape}, Y:{y_full.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jAk-UQCjKecT",
    "outputId": "9566d67a-b78b-4809-bb94-8f605b065db6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2]])"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# peek data matrix\n",
    "X_full[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YdzMURX2KVdO",
    "outputId": "af5fc3ac-b391-4769-de47-44cea4f566c8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['setosa'],\n",
       "       ['setosa'],\n",
       "       ['setosa'],\n",
       "       ['setosa'],\n",
       "       ['setosa']], dtype='<U10')"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# peek target vector\n",
    "y_full[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kl8UFh1OegbJ"
   },
   "source": [
    "Separamos el dataset en train y test para medir performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LKP_QmWCIECs",
    "outputId": "07798c6a-aa54-430e-d46d-becc2a4315ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 90) (1, 90) (4, 60) (1, 60)\n"
     ]
    }
   ],
   "source": [
    "# preparing data, train - test validation\n",
    "# 70-30 split\n",
    "from sklearn.model_selection import train_test_split\n",
    "# NOTE: los parametros X, y, test_sz, random_state no se estaban utilizando. Corregimos el codigo.\n",
    "def split_transpose(X, y, test_sz, random_state):\n",
    "    # split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_sz, random_state=random_state)\n",
    "\n",
    "    # transpose so observations are column vectors\n",
    "    return X_train.T, y_train.T, X_test.T, y_test.T\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "  return (y_true == y_pred).mean()\n",
    "\n",
    "train_x, train_y, test_x, test_y = split_transpose(X_full, y_full, 0.4, rng_seed)\n",
    "\n",
    "print(train_x.shape, train_y.shape, test_x.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LwgXFPbJemb_"
   },
   "source": [
    "Entrenamos un QDA y medimos su accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "id": "dGIf2TA5SpoT"
   },
   "outputs": [],
   "source": [
    "qda = QDA()\n",
    "\n",
    "qda.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c0Q30DyLWpTL",
    "outputId": "dbccae86-840c-412f-ed97-22cfac21238a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (apparent) error is 0.0111 while test error is 0.0167\n"
     ]
    }
   ],
   "source": [
    "train_acc = accuracy(train_y, qda.predict(train_x))\n",
    "test_acc = accuracy(test_y, qda.predict(test_x))\n",
    "print(f\"Train (apparent) error is {1-train_acc:.4f} while test error is {1-test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-QcLtNNIevC_"
   },
   "source": [
    "Con el magic %%timeit podemos estimar el tiempo que tarda en correr una celda en base a varias ejecuciones. Por poner un ejemplo, acá vamos a estimar lo que tarda un ciclo completo de QDA y también su inferencia (predicción).\n",
    "\n",
    "Ojo! a veces [puede ser necesario ejecutarlo varias veces](https://stackoverflow.com/questions/10994405/python-timeit-results-cached-instead-of-calculated) para obtener resultados consistentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vnZT-HN2fUuW",
    "outputId": "2618e7c1-7a77-4285-bafb-c2880ad167a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.24 ms ± 43.6 μs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "qda.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kjFbVSqfeHUX",
    "outputId": "0254a727-a1d5-4be3-b73a-2f55d2c84a25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.34 ms ± 10.1 μs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "model = QDA()\n",
    "model.fit(train_x, train_y)\n",
    "model.predict(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Yb1V7_yXRfO"
   },
   "source": [
    "# Consigna\n",
    "\n",
    "## Implementación\n",
    "1. Entrenar un modelo QDA sobre el dataset *iris* utilizando las distribuciones *a priori* a continuación ¿Se observan diferencias?¿Por qué cree? _Pista: comparar con las distribuciones del dataset completo, **sin splitear**_.\n",
    "    1. Uniforme (cada clase tiene probabilidad 1/3)\n",
    "    2. Una clase con probabilidad 0.9, las demás 0.05 (probar las 3 combinaciones)\n",
    "2. Repetir el punto anterior para el dataset *penguin*.\n",
    "3. Implementar el modelo LDA, entrenarlo y testearlo contra los mismos sets que QDA ¿Se observan diferencias? ¿Podría decirse que alguno de los dos es notoriamente mejor que el otro?\n",
    "4. Utilizar otros 2 (dos) valores de *random seed* para obtener distintos splits de train y test, y repetir la comparación del punto anterior ¿Las conclusiones previas se mantienen?\n",
    "5. Estimar y comparar los tiempos de predicción de las clases `QDA` y `TensorizedQDA`. De haber diferencias ¿Cuáles pueden ser las causas?\n",
    "\n",
    "\n",
    "**Sugerencia:** puede resultar de utilidad para los puntos de comparación utilizar tablas del siguiente estilo:\n",
    "\n",
    "<center>\n",
    "\n",
    "Modelo | Dataset | Seed | Error (train) | Error (test)\n",
    ":---: | :---: | :---: | :---: | :---:\n",
    "QDA | Iris | 125 | 0.55 | 0.85\n",
    "LDA | Iris | 125 | 0.22 | 0.8\n",
    "\n",
    "</center>\n",
    "\n",
    "## Preguntas teóricas\n",
    "\n",
    "1. En LDA se menciona que la función a maximizar puede ser, mediante operaciones, convertida en:\n",
    "$$\n",
    "\\log{f_j(x)} =  \\mu_j^T \\Sigma^{-1} (x- \\frac{1}{2} \\mu_j) + C'\n",
    "$$\n",
    "Mostrar los pasos por los cuales se llega a dicha expresión.\n",
    "2. Explicar, utilizando las respectivas funciones a maximizar, por qué QDA y LDA son \"quadratic\" y \"linear\".\n",
    "3. La implementación de QDA estima la probabilidad condicional utilizando `0.5*np.log(det(inv_cov)) -0.5 * unbiased_x.T @ inv_cov @ unbiased_x` que no es *exactamente* lo descrito en el apartado teórico ¿Cuáles son las diferencias y por qué son expresiones equivalentes?\n",
    "\n",
    "El espíritu de esta componente práctica es la de establecer un mínimo de trabajo aceptable para su entrega; se invita al alumno a explorar otros aspectos que generen curiosidad, sin sentirse de ninguna manera limitado por la consigna.\n",
    "\n",
    "## Ejercicio teórico\n",
    "\n",
    "Sea una red neuronal de dos capas, la primera de 3 neuronas y la segunda de 1 con los parámetros inicializados con los siguientes valores:\n",
    "$$\n",
    "w^{(1)} =\n",
    "\\begin{pmatrix}\n",
    "0.1 & -0.5 \\\\\n",
    "-0.3 & -0.9 \\\\\n",
    "0.8 & 0.02\n",
    "\\end{pmatrix},\n",
    "b^{(1)} = \\begin{pmatrix}\n",
    "0.1 \\\\\n",
    "0.5 \\\\\n",
    "0.8\n",
    "\\end{pmatrix},\n",
    "w^{(2)} =\n",
    "\\begin{pmatrix}\n",
    "-0.4 & 0.2 & -0.5\n",
    "\\end{pmatrix},\n",
    "b^{(2)} = 0.7\n",
    "$$\n",
    "\n",
    "y donde cada capa calcula su salida vía\n",
    "\n",
    "$$\n",
    "y^{(i)} = \\sigma (w^{(i)} \\cdot x^{(i)}+b^{(i)})\n",
    "$$\n",
    "\n",
    "donde $\\sigma (z) = \\frac{1}{1+e^{-z}}$ es la función sigmoidea .\n",
    "\n",
    "\\\\\n",
    "Dada la observación $x=\\begin{pmatrix}\n",
    "1.8 \\\\\n",
    "-3.4\n",
    "\\end{pmatrix}$, $y=5$ y la función de costo $J(\\theta)=\\frac{1}{2}(\\hat{y}_\\theta-y)^2$, calcular las derivadas de J respecto de cada parámetro $w^{(1)}$, $w^{(2)}$, $b^{(1)}$, $b^{(2)}$.\n",
    "\n",
    "*Nota: Con una sigmoidea a la salida jamás va a poder estimar el 5 \"pedido\", pero eso no afecta al mecanismo de backpropagation!*\n",
    "\n",
    "## Preguntas en el código\n",
    "Previamente las preguntas \"técnicas\" en comentarios en el código eran parte del TP, y buscaban que el alumno logre entrar en el detalle de por qué cada linea de código es como es y en el orden en el que está. Ya no forman parte de la consigna, pero se aconseja al alumno intentar responderlas. Las respuestas a las mismas se encuentran en un archivo separado.\n",
    "\n",
    "## Opcional\n",
    "\n",
    "### QDA\n",
    "\n",
    "Debido a la forma cuadrática de QDA, no se puede predecir para *n* observaciones en una sola pasada (utilizar $X \\in \\mathbb{R}^{p \\times n}$ en vez de $x \\in \\mathbb{R}^p$) sin pasar por una matriz de *n x n* en donde se computan todas las interacciones entre observaciones. Se puede acceder al resultado recuperando sólo la diagonal de dicha matriz, pero resulta ineficiente en tiempo y (especialmente) en memoria. Aún así, es *posible* que el modelo funcione más rápido.\n",
    "\n",
    "1. Implementar el modelo `FasterQDA` (se recomienda heredarlo de TensorizedQDA) de manera de eliminar el ciclo for en el método predict.\n",
    "2. Comparar los tiempos de predicción de `FasterQDA` con `TensorizedQDA` y `QDA`\n",
    "3. Mostrar (puede ser con un print) dónde aparece la mencionada matriz de *n x n*, donde *n* es la cantidad de observaciones a predecir.\n",
    "4.Demostrar\n",
    "$$\n",
    "diag(A \\cdot B) = \\sum_{cols} A \\odot B^T = np.sum(A \\odot B^T, axis=1)\n",
    "$$ es decir, que se puede \"esquivar\" la matriz de *n x n* usando matrices de *n x p*.\n",
    "5.Utilizar la propiedad antes demostrada para reimplementar la predicción del modelo `FasterQDA` de forma eficiente. ¿Hay cambios en los tiempos de predicción?\n",
    "\n",
    "\n",
    "### LDA\n",
    "\n",
    "1. \"Tensorizar\" el modelo LDA y comparar sus tiempos de predicción con el modelo antes implementado. *Notar que, en modo tensorizado, se puede directamente precomputar $\\mu^T \\cdot \\Sigma^{-1} \\in \\mathbb{R}^{k \\times 1 \\times p}$ y guardar eso en vez de $\\Sigma^{-1}$.*\n",
    "2. LDA no sufre del problema antes descrito de QDA debido a que no computa productos internos, por lo que no tiene un verdadero costo extra en memoria predecir \"en batch\". Implementar el modelo `FasterLDA` y comparar sus tiempos de predicción con las versiones anteriores de LDA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RESPUESTAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Entrenar un modelo QDA sobre el dataset *iris* utilizando las distribuciones *a priori* a continuación ¿Se observan diferencias?¿Por qué cree? _Pista: comparar con las distribuciones del dataset completo, **sin splitear**_.\n",
    "    1. Uniforme (cada clase tiene probabilidad 1/3)\n",
    "    2. Una clase con probabilidad 0.9, las demás 0.05 (probar las 3 combinaciones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 1.1 Entrenar un modelo QDA sobre el dataset *iris* utilizando las distribuciones *a priori* Uniforme (cada clase tiene probabilidad 1/3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CODIGO DE SETUP**\n",
    "\n",
    "El siguiente codigo de setup se utiliza para **todas las pruebas** (tanto QDA como LDA).\n",
    "Simplemente se descomentan las lineas para el dataset que queremos utilizar\n",
    "ejemplo: Si queremos utilizar el penguin quedaria\n",
    "```\n",
    "    # Cargar el dataset iris\n",
    "    # X_full, y_full = get_iris_dataset()\n",
    "    # Cargar el dataset penguin\n",
    "    X_full, y_full = get_penguins()\n",
    "```\n",
    "\n",
    "Si queremos probar sin split quedaria:\n",
    "```\n",
    "    # [Split]: Dividir el dataset entre test y train \n",
    "    # train_x, train_y, test_x, test_y = split_transpose(X_full, y_full, test_sz, seed)\n",
    "    # [Sin Split]: Dataset completo sin split\n",
    "    train_x, train_y, test_x, test_y = X_full.T, y_full.T, X_full.T, y_full.T\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 105) (1, 105) (4, 45) (1, 45)\n"
     ]
    }
   ],
   "source": [
    "# *** CODIGO DE SETUP *** \n",
    "\n",
    "# Cargar el dataset iris\n",
    "X_full, y_full = get_iris_dataset()\n",
    "# Cargar el dataset penguin\n",
    "# X_full, y_full = get_penguins()\n",
    "\n",
    "# Seed\n",
    "seed = 16\n",
    "# Test size\n",
    "test_sz = 0.3 # 30%\n",
    "# [Split]: Dividir el dataset entre test y train \n",
    "train_x, train_y, test_x, test_y = split_transpose(X_full, y_full, test_sz, seed)\n",
    "# [Sin Split]: Dataset completo sin split\n",
    "# train_x, train_y, test_x, test_y = X_full.T, y_full.T, X_full.T, y_full.T\n",
    "print(train_x.shape, train_y.shape, test_x.shape, test_y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Uniforme (cada clase tiene probabilidad 1/3)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* QDA: Train (apparent) error is 0.0381 while test error is 0.0222\n",
      "Error (train): 3.81%\n",
      "Error (test): 2.22%\n"
     ]
    }
   ],
   "source": [
    "qda = QDA()\n",
    "qda.fit(train_x, train_y, a_priori=[0.33333333, 0.33333333,  0.33333333])\n",
    "\n",
    "y_train_pred = qda.predict(train_x)\n",
    "y_test_pred = qda.predict(test_x)\n",
    "qda_train_acc = accuracy(train_y, y_train_pred)\n",
    "qda_test_acc = accuracy(test_y, y_test_pred)\n",
    "print(f\"* QDA: Train (apparent) error is {1-qda_train_acc:.4f} while test error is {1-qda_test_acc:.4f}\")\n",
    "\n",
    "# Calculate train and test errors\n",
    "error_train = np.mean(y_train_pred != train_y)\n",
    "error_test = np.mean(y_test_pred != test_y)\n",
    "\n",
    "print(f\"Error (train): {error_train:.2%}\")\n",
    "print(f\"Error (test): {error_test:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 1.2 Entrenar un modelo QDA sobre el dataset *iris* \n",
    "utilizando las distribuciones *a priori* Una clase con probabilidad 0.9, las demás 0.05 (probar las 3 combinaciones)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Primera clase con probabilidad 0.9, las demás 0.05**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* QDA: Train (apparent) error is 0.0381 while test error is 0.0222\n",
      "Error (train): 3.81%\n",
      "Error (test): 2.22%\n"
     ]
    }
   ],
   "source": [
    "qda = QDA()\n",
    "# Primera clase con probabilidad 0.9, las demás 0.05\n",
    "qda.fit(train_x, train_y, a_priori=[0.9, 0.05,  0.05])\n",
    "\n",
    "y_train_pred = qda.predict(train_x)\n",
    "y_test_pred = qda.predict(test_x)\n",
    "qda_train_acc = accuracy(train_y, y_train_pred)\n",
    "qda_test_acc = accuracy(test_y, y_test_pred)\n",
    "print(f\"* QDA: Train (apparent) error is {1-qda_train_acc:.4f} while test error is {1-qda_test_acc:.4f}\")\n",
    "\n",
    "# Calculate train and test errors\n",
    "error_train = np.mean(y_train_pred != train_y)\n",
    "error_test = np.mean(y_test_pred != test_y)\n",
    "\n",
    "print(f\"Error (train): {error_train:.2%}\")\n",
    "print(f\"Error (test): {error_test:.2%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Segunda clase con probabilidad 0.05, 0.9 y 0.05**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* QDA: Train (apparent) error is 0.0381 while test error is 0.0444\n",
      "Error (train): 3.81%\n",
      "Error (test): 4.44%\n"
     ]
    }
   ],
   "source": [
    "qda = QDA()\n",
    "# Segunda clase con probabilidad 0.05, 0.9 y 0.05\n",
    "qda.fit(train_x, train_y, a_priori=[0.05, 0.9,  0.05])\n",
    "\n",
    "y_train_pred = qda.predict(train_x)\n",
    "y_test_pred = qda.predict(test_x)\n",
    "qda_train_acc = accuracy(train_y, y_train_pred)\n",
    "qda_test_acc = accuracy(test_y, y_test_pred)\n",
    "print(f\"* QDA: Train (apparent) error is {1-qda_train_acc:.4f} while test error is {1-qda_test_acc:.4f}\")\n",
    "\n",
    "# Calculate train and test errors\n",
    "error_train = np.mean(y_train_pred != train_y)\n",
    "error_test = np.mean(y_test_pred != test_y)\n",
    "\n",
    "print(f\"Error (train): {error_train:.2%}\")\n",
    "print(f\"Error (test): {error_test:.2%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tercera clase con probabilidad 0.05, 0.05 y 0.9**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* QDA: Train (apparent) error is 0.0286 while test error is 0.0667\n",
      "Error (train): 2.86%\n",
      "Error (test): 6.67%\n"
     ]
    }
   ],
   "source": [
    "qda = QDA()\n",
    "# Tercera clase con probabilidad 0.05, 0.05 y 0.9\n",
    "qda.fit(train_x, train_y, a_priori=[0.05, 0.05,  0.9])\n",
    "\n",
    "y_train_pred = qda.predict(train_x)\n",
    "y_test_pred = qda.predict(test_x)\n",
    "qda_train_acc = accuracy(train_y, y_train_pred)\n",
    "qda_test_acc = accuracy(test_y, y_test_pred)\n",
    "print(f\"* QDA: Train (apparent) error is {1-qda_train_acc:.4f} while test error is {1-qda_test_acc:.4f}\")\n",
    "\n",
    "# Calculate train and test errors\n",
    "error_train = np.mean(y_train_pred != train_y)\n",
    "error_test = np.mean(y_test_pred != test_y)\n",
    "\n",
    "print(f\"Error (train): {error_train:.2%}\")\n",
    "print(f\"Error (test): {error_test:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo | Dataset | Seed | a_priori | Split | Error (train) | Error (test)\n",
    ":---: | :---: | :---: | :---: | :---: | :---: | :---:\n",
    "QDA | Iris | 125 | [1/3, 1/3, 1/3] | 70/30 | 2.86% | 0.00%\n",
    "QDA | Iris | 125 | [0.9, 0.05, 0.05] | 70/30 | 2.86% | 0.00%\n",
    "QDA | Iris | 125 | [0.05, 0.9, 0.05] | 70/30 | 6.67% | 2.22%\n",
    "QDA | Iris | 125 | [0.05, 0.05, 0.9] | 70/30 | 4.76% | 0.00%\n",
    "QDA | Iris | 125 | [1/3, 1/3, 1/3] | 100 | 2.00% | 2.00%\n",
    "QDA | Iris | 125 | [0.9, 0.05, 0.05] | 100 | 2.00% | 2.00%\n",
    "QDA | Iris | 125 | [0.05, 0.9, 0.05] | 100 | 3.33% | 3.33%\n",
    "QDA | Iris | 125 | [0.05, 0.05, 0.9] | 100 | 4.00% | 4.00%\n",
    " |  |  |  |  |  |\n",
    "QDA | Penguin | 125 | [1/3, 1/3, 1/3] | 70/30 | 0.84% | 0.97%\n",
    "QDA | Penguin | 125 | [0.9, 0.05, 0.05] | 70/30 | 1.67% | 1.94%\n",
    "QDA | Penguin | 125 | [0.05, 0.9, 0.05] | 70/30 | 4.60% | 6.80%\n",
    "QDA | Penguin | 125 | [0.05, 0.05, 0.9] | 70/30 | 0.84% | 0.97%\n",
    "QDA | Penguin | 125 | [1/3, 1/3, 1/3] | 100 | 0.88% | 0.88%\n",
    "QDA | Penguin | 125 | [0.9, 0.05, 0.05] | 100 | 1.75% | 1.75%\n",
    "QDA | Penguin | 125 | [0.05, 0.9, 0.05] | 100 | 3.51% | 3.51%\n",
    "QDA | Penguin | 125 | [0.05, 0.05, 0.9] | 100 | 0.88% | 0.88%\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Implementar el modelo **LDA**, entrenarlo y testearlo contra los mismos sets que QDA \n",
    "* ¿Se observan diferencias?\n",
    "* ¿Podría decirse que alguno de los dos es notoriamente mejor que el otro?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Implementation LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Analisis Discriminante Lineal y Cuadratico](https://www.youtube.com/watch?v=Meo0odkRFfU&list=PLN2e9R_DoC0SDbv3C_B-LCpuliGtvdQvg&index=1&ab_channel=AndresFarall)\n",
    "class LDA(BaseBayesianClassifier):\n",
    "    \"\"\"\n",
    "    Este método calcula y almacena los parámetros necesarios para el modelo. Es el paso de \"entrenamiento\" o ajuste del modelo.\n",
    "    \"\"\"\n",
    "    def _fit_params(self, X, y):\n",
    "        # Asegura que y (el vector de etiquetas) sea un arreglo unidimensional. Esto facilita las comparaciones e indexaciones más adelante.\n",
    "        # Ejemplo: Si y es una matriz columna de forma (n,1), después del flatten, será un vector de forma (n,).\n",
    "        y_flat = y.flatten()\n",
    "        # Calcula la matriz de covarianza compartida (Σ) para todas las clases combinadas.\n",
    "        # bias=True: Normaliza por n (número de muestras) en lugar de n − 1. Esto se alinea con los supuestos teóricos del modelo LDA.\n",
    "        self.shared_cov = np.cov(X, bias=True)\n",
    "        # Calcula la inversa de la matriz de covarianza compartida, que se usará posteriormente para evaluar las probabilidades condicionales.\n",
    "        # La matriz inversa permite medir la \"dispersión\" de los datos considerando las correlaciones entre las características.\n",
    "        self.inv_shared_cov = np.linalg.inv(self.shared_cov)    \n",
    "\n",
    "        # Calcula los vectores de media (μj)​ para cada clase j\n",
    "        # X[:, y_flat == idx] : Filtra las columnas de X correspondientes a la clase j (donde y = idx)\n",
    "        # .mean(axis=1, keepdims=True): Calcula la media para cada fila (característica), manteniendo la forma de matriz (columna).\n",
    "        self.means = [\n",
    "            X[:, y_flat == idx].mean(axis=1, keepdims=True)\n",
    "            for idx in range(len(self.log_a_priori))\n",
    "        ]\n",
    "        # self.means : Es una lista donde cada elemento es un vector columna (μj) de medias para cada clase.\n",
    "    \"\"\"\n",
    "    Este método calcula el logaritmo de la probabilidad condicional para una observación x dada y una clase j.\n",
    "    \"\"\"\n",
    "    def _predict_log_conditional(self, x, class_idx):\n",
    "        # Resta el vector de medias (μj) correspondiente a la clase j de la observación x.\n",
    "        # Esto genera un vector desplazado (x − μj) que mide qué tan lejos está x del centro de la clase j.\n",
    "        unbiased_x = x - self.means[class_idx]\n",
    "        # Este término mide qué tan probable es que x pertenezca a la clase j, considerando las correlaciones entre las características (por Σ^−1)\n",
    "        return -0.5 * unbiased_x.T @ self.inv_shared_cov @ unbiased_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 3.1 Entrenar un modelo LDA sobre el dataset *iris* y *penguin* utilizando las distribuciones *a priori* Uniforme (cada clase tiene probabilidad 1/3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Uniforme (cada clase tiene probabilidad 1/3)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* LDA: Train (apparent) error is 0.1048 while test error is 0.2000\n",
      "Error (train): 10.48%\n",
      "Error (test): 20.00%\n"
     ]
    }
   ],
   "source": [
    "lda = LDA()\n",
    "lda.fit(train_x, train_y, a_priori=[0.33333333, 0.33333333,  0.33333333])\n",
    "\n",
    "y_train_pred = lda.predict(train_x)\n",
    "y_test_pred = lda.predict(test_x)\n",
    "lda_train_acc = accuracy(train_y, y_train_pred)\n",
    "lda_test_acc = accuracy(test_y, y_test_pred)\n",
    "print(f\"* LDA: Train (apparent) error is {1-lda_train_acc:.4f} while test error is {1-lda_test_acc:.4f}\")\n",
    "\n",
    "# Calculate train and test errors\n",
    "error_train = np.mean(y_train_pred != train_y)\n",
    "error_test = np.mean(y_test_pred != test_y)\n",
    "\n",
    "print(f\"Error (train): {error_train:.2%}\")\n",
    "print(f\"Error (test): {error_test:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 3.2 Entrenar un modelo LDA sobre el dataset *iris* y *penguin*\n",
    "utilizando las distribuciones *a priori* Una clase con probabilidad 0.9, las demás 0.05 (probar las 3 combinaciones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Primera clase con probabilidad 0.9, las demás 0.05**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* LDA: Train (apparent) error is 0.5048 while test error is 0.5333\n",
      "Error (train): 50.48%\n",
      "Error (test): 53.33%\n"
     ]
    }
   ],
   "source": [
    "lda = LDA()\n",
    "# Primera clase con probabilidad 0.9, las demás 0.05\n",
    "lda.fit(train_x, train_y, a_priori=[0.9, 0.05,  0.05])\n",
    "\n",
    "y_train_pred = lda.predict(train_x)\n",
    "y_test_pred = lda.predict(test_x)\n",
    "lda_train_acc = accuracy(train_y, y_train_pred)\n",
    "lda_test_acc = accuracy(test_y, y_test_pred)\n",
    "print(f\"* LDA: Train (apparent) error is {1-lda_train_acc:.4f} while test error is {1-lda_test_acc:.4f}\")\n",
    "\n",
    "# Calculate train and test errors\n",
    "error_train = np.mean(y_train_pred != train_y)\n",
    "error_test = np.mean(y_test_pred != test_y)\n",
    "\n",
    "print(f\"Error (train): {error_train:.2%}\")\n",
    "print(f\"Error (test): {error_test:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Segunda clase con probabilidad 0.9, las demás 0.05**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* LDA: Train (apparent) error is 0.6286 while test error is 0.5778\n",
      "Error (train): 62.86%\n",
      "Error (test): 57.78%\n"
     ]
    }
   ],
   "source": [
    "lda = LDA()\n",
    "# Segunda clase con probabilidad 0.9, las demás 0.05\n",
    "lda.fit(train_x, train_y, a_priori=[0.05, 0.9,  0.05])\n",
    "\n",
    "y_train_pred = lda.predict(train_x)\n",
    "y_test_pred = lda.predict(test_x)\n",
    "lda_train_acc = accuracy(train_y, y_train_pred)\n",
    "lda_test_acc = accuracy(test_y, y_test_pred)\n",
    "print(f\"* LDA: Train (apparent) error is {1-lda_train_acc:.4f} while test error is {1-lda_test_acc:.4f}\")\n",
    "\n",
    "# Calculate train and test errors\n",
    "error_train = np.mean(y_train_pred != train_y)\n",
    "error_test = np.mean(y_test_pred != test_y)\n",
    "\n",
    "print(f\"Error (train): {error_train:.2%}\")\n",
    "print(f\"Error (test): {error_test:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tercera clase con probabilidad 0.9, las demás 0.05**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* LDA: Train (apparent) error is 0.5429 while test error is 0.5556\n",
      "Error (train): 54.29%\n",
      "Error (test): 55.56%\n"
     ]
    }
   ],
   "source": [
    "lda = LDA()\n",
    "# Tercera clase con probabilidad 0.9, las demás 0.05\n",
    "lda.fit(train_x, train_y, a_priori=[0.05, 0.05,  0.9])\n",
    "\n",
    "y_train_pred = lda.predict(train_x)\n",
    "y_test_pred = lda.predict(test_x)\n",
    "lda_train_acc = accuracy(train_y, y_train_pred)\n",
    "lda_test_acc = accuracy(test_y, y_test_pred)\n",
    "print(f\"* LDA: Train (apparent) error is {1-lda_train_acc:.4f} while test error is {1-lda_test_acc:.4f}\")\n",
    "\n",
    "# Calculate train and test errors\n",
    "error_train = np.mean(y_train_pred != train_y)\n",
    "error_test = np.mean(y_test_pred != test_y)\n",
    "\n",
    "print(f\"Error (train): {error_train:.2%}\")\n",
    "print(f\"Error (test): {error_test:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo | Dataset | Seed | a_priori | Split | Error (train) | Error (test)\n",
    ":---: | :---: | :---: | :---: | :---: | :---: | :---:\n",
    "LDA | Iris | 125 | [1/3, 1/3, 1/3] | 70/30 | 12.38% | 13.33%\n",
    "LDA | Iris | 125 | [0.9, 0.05, 0.05] | 70/30 | 54.29% | 46.67%\n",
    "LDA | Iris | 125 | [0.05, 0.9, 0.05] | 70/30 | 63.81% | 55.56%\n",
    "LDA | Iris | 125 | [0.05, 0.05, 0.9] | 70/30 | 53.33% | 48.89%\n",
    "LDA | Iris | 125 | [1/3, 1/3, 1/3] | 100 | 13.33% | 13.33%\n",
    "LDA | Iris | 125 | [0.9, 0.05, 0.05] | 100 | 51.33% | 51.33%\n",
    "LDA | Iris | 125 | [0.05, 0.9, 0.05] | 100 | 62.67% | 62.67%\n",
    "LDA | Iris | 125 | [0.05, 0.05, 0.9] | 100 | 55.33% | 55.33%\n",
    " |  |  |  |  |  | \n",
    "LDA | Penguin | 125 | [1/3, 1/3, 1/3] | 70/30 | 0.84% | 0.97% \n",
    "LDA | Penguin | 125 | [0.9, 0.05, 0.05] | 70/30 | 44.77% | 37.86%\n",
    "LDA | Penguin | 125 | [0.05, 0.9, 0.05] | 70/30 | 38.49% | 44.66%\n",
    "LDA | Penguin | 125 | [0.05, 0.05, 0.9] | 70/30 | 45.19% | 39.81%\n",
    "LDA | Penguin | 125 | [1/3, 1/3, 1/3] | 100 | 0.88% | 0.88%\n",
    "LDA | Penguin | 125 | [0.9, 0.05, 0.05] | 100 | 42.98% | 42.98%\n",
    "LDA | Penguin | 125 | [0.05, 0.9, 0.05] | 100 | 40.64% | 40.64%\n",
    "LDA | Penguin | 125 | [0.05, 0.05, 0.9] | 100 | 43.57% | 43.57%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ¿Se observan diferencias?\n",
    "    - Comparando ambas tablas vemos que el QDA produce errors (train y test) mas pequeños que los producidos por LDA.\n",
    "* ¿Podría decirse que alguno de los dos es notoriamente mejor que el otro?\n",
    "    - De la respuesta anterior podemos decir que QDA performa mejor que LDA.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Utilizar otros 2 (dos) valores de *random seed* para obtener distintos splits de train y test, y repetir la comparación del punto anterior ¿Las conclusiones previas se mantienen?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se realiza la comparacion con Seeds de 125, 64 y 16. En todos los casos el split es 70-30 t la distribucion a priori es 1/3 para todas las clases:\n",
    "\n",
    "Modelo | Dataset | Seed | a_priori | Split | Error (train) | Error (test)\n",
    ":---: | :---: | :---: | :---: | :---: | :---: | :---:\n",
    "QDA | Iris | 125 | [1/3, 1/3, 1/3] | 70/30 | 2.86% | 0.00%\n",
    "QDA | Iris | 64 | [1/3, 1/3, 1/3] | 70/30 | 0.00% | 4.44%   \n",
    "QDA | Iris | 16 |  [1/3, 1/3, 1/3] | 70/30 | 3.81% |2.22%   \n",
    "QDA | Penguin | 125 | [1/3, 1/3, 1/3] | 70/30 | 0.84% | 0.97%\n",
    "QDA | Penguin | 64 | [1/3, 1/3, 1/3] | 70/30 | 0.84% | 1.94%\n",
    "QDA | Penguin | 16 |  [1/3, 1/3, 1/3] | 70/30 | 1.26% | 0.97%\n",
    "|  |  |  |  |  | \n",
    "LDA | Iris | 125 | [1/3, 1/3, 1/3] | 70/30 | 12.38% | 13.33%\n",
    "LDA | Iris | 64 | [1/3, 1/3, 1/3] | 70/30 | 14.29% | 11.11% \n",
    "LDA | Iris | 16 |  [1/3, 1/3, 1/3] | 70/30 | 10.48% | 20.00%\n",
    "LDA | Penguin | 125 | [1/3, 1/3, 1/3] | 70/30 | 0.84% | 0.97%\n",
    "LDA | Penguin | 64 | [1/3, 1/3, 1/3] | 70/30 | 0.84% | 0.97%\n",
    "LDA | Penguin | 16 |  [1/3, 1/3, 1/3] | 70/30 | 1.26% | 0.00%\n",
    "\n",
    "\n",
    "¿Las conclusiones previas se mantienen?\n",
    "- Vemos que las conclusiones se mantienen, siendo la performance QDA superior a la del LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Estimar y comparar los tiempos de predicción de las clases `QDA` y `TensorizedQDA`. De haber diferencias ¿Cuáles pueden ser las causas?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Estimar los tiempos de predicción de `TensorizedQDA`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tensorized_qda = TensorizedQDA()\n",
    "tensorized_qda.fit(train_x, train_y, a_priori=[0.33333333, 0.33333333,  0.33333333])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "885 μs ± 52.9 μs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "tensorized_qda.predict(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "qda = QDA()\n",
    "qda.fit(train_x, train_y, a_priori=[0.33333333, 0.33333333,  0.33333333])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.16 ms ± 74.7 μs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "qda.predict(train_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo | Dataset | Seed | a_priori | Split | Performance \n",
    ":---: | :---: | :---: | :---: | :---: | :---: \n",
    "Tensorized QDA | Penguins | 125 | [1/3, 1/3, 1/3] | 70/30 | 2.7 ms ± 112 μs \n",
    "QDA | Penguins | 125 | [1/3, 1/3, 1/3] | 70/30 | 7.23 ms ± 146 μs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De haber diferencias ¿Cuáles pueden ser las causas?\n",
    "- El Tensorized QDA performa ~2.7 veces mas rapido que el QDA y esto se debe a que cuenta con una implementacion mas de la funcion `_predict_log_conditionals`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparando como implementa cada modelo la funcion `_predict_log_conditionals`:\n",
    "* `QDA` calcula la probabilidad condicional logarítmica para una clase a la vez, iterando sobre las clases para computar `x − μ` productos internos y determinantes.\n",
    "\n",
    "* `TensorizedQDA` calcula `x − μ` productos internos y determinantes para todas las clases en un solo paso usando operaciones tensoriales:\n",
    "    - `unbiased_x` = `x − tensor_means`: Hace un broadcast de x a través de todas las clases.\n",
    "    - `inner_prod` = `unbiased_xT⋅tensor_inv_cov⋅unbiased_x`: Multiplicación tensorial eficiente a través de todas las clases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preguntas Teoricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "!['Pregunta 1'](pregunta_teorica_1.jpg) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!['Pregunta 2'](pregunta_teorica_2.jpg) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!['Pregunta 3'](pregunta_teorica_3.jpg) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio Teorico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!['Pregunta 1'](ejercicio_teorico_1.jpg) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!['Pregunta 2'](ejercicio_teorico_2.jpg) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!['Pregunta 3'](ejercicio_teorico_3.jpg) "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "intro_ai_311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
